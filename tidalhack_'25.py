# -*- coding: utf-8 -*-
"""TidalHack '25.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MbeDLhG6_7GIJV2uzQNeZkSMpxJR8Lig
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.layers import (
    Input, RandomRotation, RandomZoom, RandomTranslation, RandomContrast,
    Conv2D, MaxPooling2D, Flatten, Dense, Dropout)

from google.colab import drive
drive.mount('/content/drive')

train = pd.read_csv('/content/drive/MyDrive/ASL Project/sign_mnist_train.csv')
test = pd.read_csv('/content/drive/MyDrive/ASL Project/sign_mnist_test.csv')

train.head()

# Separate features and labels
X_train = train.drop('label', axis=1).values
y_train = train['label'].values
X_test = test.drop('label', axis=1).values
y_test = test['label'].values

# Normalize pixel values (0–255 → 0–1)
X_train = X_train / 255.0
X_test = X_test / 255.0

# Reshape to (28, 28, 1) for CNN input
X_train = X_train.reshape(-1, 28, 28, 1)
X_test = X_test.reshape(-1, 28, 28, 1)

# One-hot encode labels
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

print("Train shape:", X_train.shape)
print("Test shape:", X_test.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(25, activation='softmax')  # 25 classes for A–Y (no J, Z)
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=128,
    validation_split=0.2,
    verbose=1
)

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_acc*100:.2f}%")

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.legend()
plt.title('Model Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.show()

model = Sequential([
    # --- Data Augmentation Layers ---
    Input(shape=(28, 28, 1)),
    RandomRotation(0.05),
    RandomZoom(0.05),
    RandomTranslation(0.05, 0.05),
    RandomContrast(0.05),

    # --- Convolutional Layers ---
    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),

    # 25 output classes (A–Y, no J/Z)
    Dense(25, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    X_train, y_train,
    epochs=15,          # try 10–20 depending on runtime
    batch_size=128,
    validation_data=(X_test, y_test),
    verbose=1
)

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_acc*100:.2f}%")

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.legend()
plt.title('Accuracy over epochs with augmentation')
plt.show()

model.summary()

model.save('/content/drive/MyDrive/ASL_Project/asl_cnn_augmented.keras')